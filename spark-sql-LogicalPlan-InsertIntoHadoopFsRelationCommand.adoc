== [[InsertIntoHadoopFsRelationCommand]] InsertIntoHadoopFsRelationCommand Logical Command

`InsertIntoHadoopFsRelationCommand` is a <<spark-sql-LogicalPlan-DataWritingCommand.adoc#, DataWritingCommand>> that writes the data of the <<query, query>> out in the given <<fileFormat, FileFormat>>.

`InsertIntoHadoopFsRelationCommand` is <<creating-instance, created>> when:

* `DataSource` is requested to <<spark-sql-DataSource.adoc#planForWritingFileFormat, planForWritingFileFormat>>

* <<spark-sql-Analyzer-DataSourceAnalysis.adoc#, DataSourceAnalysis>> post-hoc logical resolution rule is executed (and resolves a <<spark-sql-LogicalPlan-InsertIntoTable.adoc#, InsertIntoTable>> logical operator with a <<spark-sql-BaseRelation-HadoopFsRelation.adoc#, HadoopFsRelation>>)

=== [[run]] Executing Logical Command -- `run` Method

[source, scala]
----
run(session: SparkSession): Seq[Row]
----

NOTE: `run` is part of <<spark-sql-LogicalPlan-RunnableCommand.adoc#run, RunnableCommand Contract>> to execute (run) a logical command.

`run` uses the <<spark-sql-SQLConf.adoc#manageFilesourcePartitions, spark.sql.hive.manageFilesourcePartitions>> configuration property to...FIXME

CAUTION: FIXME When is the <<catalogTable, catalogTable>> defined?

CAUTION: FIXME When is `tracksPartitionsInCatalog` of `CatalogTable` enabled?

`run`...FIXME

`run` uses `SchemaUtils` to <<spark-sql-SchemaUtils.adoc#checkColumnNameDuplication, make sure that there are no duplicates>> in the <<outputColumnNames, outputColumnNames>>.

=== [[creating-instance]] Creating InsertIntoHadoopFsRelationCommand Instance

`InsertIntoHadoopFsRelationCommand` takes the following when created:

* [[outputPath]] Output Hadoop's https://hadoop.apache.org/docs/r2.7.3/api/index.html?org/apache/hadoop/fs/Path.html[Path]
* [[staticPartitions]] Static table partitions (`Map[String, String]`)
* [[ifPartitionNotExists]] `ifPartitionNotExists` flag
* [[partitionColumns]] Partition columns (`Seq[Attribute]`)
* [[bucketSpec]] <<spark-sql-BucketSpec.adoc#, BucketSpec>>
* [[fileFormat]] <<spark-sql-FileFormat.adoc#, FileFormat>>
* [[options]] Options (`Map[String, String]`)
* [[query]] <<spark-sql-LogicalPlan.adoc#, Logical plan>>
* [[mode]] `SaveMode`
* [[catalogTable]] <<spark-sql-CatalogTable.adoc#, CatalogTable>>
* [[fileIndex]] `FileIndex`
* [[outputColumnNames]] Output column names

[NOTE]
====
<<staticPartitions, staticPartitions>> may hold zero or more partitions as follows:

* Always empty when <<creating-instance, created>> when `DataSource` is requested to <<spark-sql-DataSource.adoc#planForWritingFileFormat, planForWritingFileFormat>>

* Possibly with partitions when <<creating-instance, created>> when `DataSourceAnalysis` posthoc logical resolution rule is <<spark-sql-Analyzer-DataSourceAnalysis.adoc#apply, applied>> to an <<spark-sql-LogicalPlan-InsertIntoTable.adoc#, InsertIntoTable>> logical operator over a <<spark-sql-BaseRelation-HadoopFsRelation.adoc#, HadoopFsRelation>> relation

With that, <<staticPartitions, staticPartitions>> are simply the partitions of an <<spark-sql-LogicalPlan-InsertIntoTable.adoc#, InsertIntoTable>> logical operator.
====
